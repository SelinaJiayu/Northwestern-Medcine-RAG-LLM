{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_website(url):\n",
    "    # Send a request to the given URL\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find main content\n",
    "    main_content = soup.find('div', class_='text-ckeditor aem-GridColumn aem-GridColumn--default--12')\n",
    "    if not main_content:\n",
    "        print(f\"Main content section not found for {url}\")\n",
    "        return None\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # Loop through headers h2, h3, h4 to get questions\n",
    "    for header in main_content.find_all(['h2', 'h3', 'h4']):\n",
    "        question = header.get_text(strip=True)\n",
    "        answer = []\n",
    "\n",
    "        # Collect all relevant paragraphs or list items that follow the header\n",
    "        for sibling in header.find_next_siblings():\n",
    "            if sibling.name in ['h2', 'h3', 'h4']:\n",
    "                break  # Stop at the next header\n",
    "            \n",
    "            if sibling.name == 'p':\n",
    "                answer.append(sibling.get_text(strip=True))\n",
    "            elif sibling.name == 'ul':\n",
    "                for li in sibling.find_all('li'):\n",
    "                    answer.append(li.get_text(strip=True))\n",
    "\n",
    "        # Append the question and answer to the data list\n",
    "        data.append({\"question\": question, \"answer\": ' '.join(answer)})\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = [\n",
    "    \"https://www.cancer.org/cancer/managing-cancer/treatment-types/radiation/external-beam-radiation-therapy.html\",\n",
    "    \"https://www.cancer.org/cancer/managing-cancer/treatment-types/radiation/internal-radiation-therapy-brachytherapy.html\",\n",
    "    \"https://www.cancer.org/cancer/managing-cancer/treatment-types/radiation/systemic-radiation-therapy.html\",\n",
    "    \"https://www.cancer.org/cancer/managing-cancer/treatment-types/radiation/photodynamic-therapy.html\",\n",
    "    \"https://www.cancer.org/cancer/managing-cancer/treatment-types/radiation/effects-on-different-parts-of-body.html\",\n",
    "    \"https://www.cancer.org/cancer/managing-cancer/treatment-types/radiation/safety.html\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data found for https://www.cancer.org/cancer/managing-cancer/treatment-types/radiation/external-beam-radiation-therapy.html\n",
      "No data found for https://www.cancer.org/cancer/managing-cancer/treatment-types/radiation/internal-radiation-therapy-brachytherapy.html\n",
      "Data has been scraped and saved to 'cancer.org_systemic-radiation-therapy.html.csv'\n",
      "Data has been scraped and saved to 'cancer.org_photodynamic-therapy.html.csv'\n",
      "No data found for https://www.cancer.org/cancer/managing-cancer/treatment-types/radiation/effects-on-different-parts-of-body.html\n",
      "No data found for https://www.cancer.org/cancer/managing-cancer/treatment-types/radiation/safety.html\n"
     ]
    }
   ],
   "source": [
    "for url in url_list:\n",
    "    data = scrape_website(url)\n",
    "    if data:\n",
    "        # Parse the domain name and path for the CSV file name\n",
    "        domain_name = urlparse(url).netloc.replace(\"www.\", \"\")\n",
    "        path_name = urlparse(url).path.split('/')[-1] or 'default'\n",
    "        csv_filename = f\"{domain_name}_{path_name}.csv\"\n",
    "        \n",
    "        # Convert data to DataFrame and save to CSV\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "        \n",
    "        print(f\"Data has been scraped and saved to '{csv_filename}'\")\n",
    "    else:\n",
    "        print(f\"No data found for {url}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
